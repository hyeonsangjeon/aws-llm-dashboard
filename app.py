import streamlit as st
import boto3
import json
import pandas as pd
from datetime import datetime
from aws_services import AWSResourceCollector
from bedrock_utils import BedrockService
import plotly.express as px

# ì´ˆê¸° ì„¤ì •
## Chatbotëª…, icon, layout ì„¤ì •

st.set_page_config(
    page_title="AWS Resource Monitor",
    page_icon="â˜ï¸",
    layout="wide"
)

# ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
DEBUG = True

def debug_print(message):
    if DEBUG:
        print(f"DEBUG: {message}")

# Bedrock ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
bedrock_service = BedrockService()

# ìºì‹œ ë°ì½”ë ˆì´í„°
## ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ìºì‹œ í•¨ìˆ˜ ì •ì˜
## AWS ë¦¬ì†ŒìŠ¤, ë¹„ìš© ë¶„ì„, ì˜ˆì¸¡, ì¶”ì²œ ë°ì´í„°ë¥¼ ìºì‹œ (5ë¶„) --> customizing í•„ìš”ì‹œ ë°”ê¿”ì£¼ì„¸ìš”!

@st.cache_data(ttl=300)
def fetch_aws_resources():
    debug_print("Fetching AWS resources...")
    collector = AWSResourceCollector()
    resources = collector.collect_all_resources()
    return resources

@st.cache_data(ttl=300)
def fetch_cost_analysis():
    debug_print("Fetching cost analysis...")
    collector = AWSResourceCollector()
    analysis = collector.get_cost_analysis()
    return analysis

@st.cache_data(ttl=300)
def fetch_cost_predictions():
    debug_print("Fetching cost predictions...")
    collector = AWSResourceCollector()
    predictions = collector.predict_costs()
    return predictions

@st.cache_data(ttl=300)
def fetch_recommendations():
    debug_print("Fetching recommendations...")
    collector = AWSResourceCollector()
    recommendations = collector.get_optimization_recommendations()
    return recommendations


# DatabaseConnection í´ë˜ìŠ¤
## AWSë¦¬ì†ŒìŠ¤ ë°ì´í„° ê´€ë¦¬
## ìì—°ì–´ ì¿¼ë¦¬ ì²˜ë¦¬ ë° í•„í„°ë§ ë¡œì§

class DatabaseConnection:
    def __init__(self):
        debug_print("Initializing DatabaseConnection")
        self.resources_df = fetch_aws_resources()
        
    def execute_query(self, query):
        debug_print(f"Executing query: {query}")
        try:
            filtered_df = self.resources_df.copy()
            
            # Bedrockì„ í†µí•œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            query_params = bedrock_service.process_natural_language_query(query)
            debug_print(f"Query parameters: {query_params}")
            
            if query_params:
                # ì„œë¹„ìŠ¤ íƒ€ì… í•„í„°ë§
                if query_params.get('service_type'):
                    filtered_df = filtered_df[filtered_df['service_type'] == query_params['service_type']]
                
                # ë¦¬ì „ í•„í„°ë§
                if query_params.get('region'):
                    filtered_df = filtered_df[filtered_df['region'] == query_params['region']]
                
                # ìƒíƒœ í•„í„°ë§
                if query_params.get('status'):
                    filtered_df = filtered_df[filtered_df['status'].str.lower() == query_params['status'].lower()]
            
            return filtered_df
            
        except Exception as e:
            debug_print(f"Error executing query: {str(e)}")
            return self.resources_df  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì „ì²´ ë°ì´í„° ë°˜í™˜

# ì œëª©
st.title("â˜ï¸ AWS Resource Monitor")

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "Resource Query",
    "Cost Analysis",
    "Resource Metrics",
    "Optimization",
    "AWS Expert Chat"
])

with tab1:
    debug_print("Rendering Resource Query tab")  # [ì›ë˜ ì½”ë“œ ìœ ì§€]

    # Sidebar ì˜ì—­
    with st.sidebar:
        st.header("Sample Queries")
        sample_queries = [
            "us-east-1 ë¦¬ì „ì˜ ëª¨ë“  EC2 ì¸ìŠ¤í„´ìŠ¤ ë³´ê¸°",
            "us-east-1 ë¦¬ì „ì˜ RDS ë¦¬ì†ŒìŠ¤ ëª©ë¡",
            "Lambda í•¨ìˆ˜ ëª©ë¡ ë³´ê¸°",
            "ëª¨ë“  S3 ë²„í‚· ì¡°íšŒ",
            "ì‹¤í–‰ ì¤‘ì¸ EC2 ì¸ìŠ¤í„´ìŠ¤ ë³´ê¸°"
        ]
        for query in sample_queries:
            if st.button(query):
                st.session_state['user_input'] = query

        st.header("Quick Filters")
        service_filter = st.multiselect(
            "Filter by Service",
            ["EC2", "RDS", "Lambda", "S3"],
            default=None
        )

    # ì‚¬ìš©ì ì…ë ¥ ì˜ì—­
    user_input = st.text_area(
        "Enter your question about AWS resources:",
        value=st.session_state.get('user_input', ''),
        height=100,
        placeholder="Example: Show me all EC2 instances in us-west-2"
    )

    # [ë³€ê²½ë¨] "Query Resources" ë²„íŠ¼ í´ë¦­ ì‹œ ë¬´ê±°ìš´ ì¿¼ë¦¬ë¥¼ í•œ ë²ˆ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ìºì‹±í•¨.
    if st.button("Query Resources", type="primary"):
        if user_input:
            db = DatabaseConnection()                     # [ë³€ê²½ë¨]
            results = db.execute_query(user_input)        # [ë³€ê²½ë¨]
            st.session_state['results'] = results         # [ë³€ê²½ë¨: ê²°ê³¼ ìºì‹±]
        else:
            st.warning("Please enter a query first.")

    # [ë³€ê²½ë¨] ìºì‹±ëœ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ í™”ë©´ ì—…ë°ì´íŠ¸ (ì¿¼ë¦¬ ì¬ì‹¤í–‰ ì—†ì´)
    if 'results' in st.session_state and st.session_state['results'] is not None:
        results = st.session_state['results']
        
        if not results.empty:
            st.subheader("Query Results:")
            
            # ì„œë¹„ìŠ¤ í•„í„° ì ìš©
            if service_filter:
                results = results[results['service_type'].isin(service_filter)]
            
            # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
            display_cols = ['resource_id', 'service_type', 'region', 'status']
            if 'cost' in results.columns:
                display_cols.append('cost')
            st.dataframe(results[display_cols], use_container_width=True, hide_index=True)
            
            st.subheader("Resource Details")
            # ì„ íƒí•œ resource_idì— ë”°ë¥¸ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ selectbox ì‚¬ìš©
            selected_resource = st.selectbox(
                "Select a resource to view details:",
                results['resource_id'].tolist(),
                key="selected_resource"
            )
            
            # [ë³€ê²½ë¨] ë¦¬ì†ŒìŠ¤ ìƒì„¸ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•  ë¹ˆ ì»¨í…Œì´ë„ˆ ìƒì„±
            details_placeholder = st.empty()
            
            # ì„ íƒí•œ resource_idì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            resource_data = results[results['resource_id'] == selected_resource].iloc[0]
            
            with details_placeholder.container():
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Service Type", resource_data['service_type'])
                with col2:
                    st.metric("Status", resource_data['status'])
                with col3:
                    if 'cost' in resource_data:
                        st.metric("Cost (30 days)", f"${resource_data['cost']:.2f}")
                
                # ìƒì„¸ ì •ë³´ í‘œì‹œ
                if isinstance(resource_data.get('details'), dict):
                    st.json(resource_data['details'])
                
                # íƒœê·¸ ì •ë³´ í‘œì‹œ
                if resource_data.get('tags'):
                    st.subheader("Tags")
                    try:
                        tags = json.loads(resource_data['tags'])
                        st.json(tags)
                    except Exception as e:
                        st.json(resource_data['tags'])
            
            st.success("Query executed successfully!")
        else:
            st.info("No results found for this query.")       
        
        
        
# íƒ­ 2: Cost Analysis
## ë¹„ìš© ë¶„ì„ ëŒ€ì‹œë³´ë“œ
## ì˜ˆì¸¡ ë° íŠ¸ë Œë“œ í‘œì‹œ
## Plotly ì‚¬ìš©í•˜ì—¬ ì‹œê°í™” ìˆ˜í–‰

with tab2:
    debug_print("Rendering Cost Analysis tab")
    st.header("Cost Analysis Dashboard")
    
    predictions = fetch_cost_predictions()
    if isinstance(predictions, dict) and predictions:
        st.subheader("ğŸ’° Cost Predictions")
        cols = st.columns(len(predictions))
        for idx, (service, pred_data) in enumerate(predictions.items()):
            with cols[idx]:
                st.metric(
                    label=f"{service} Cost Trend",
                    value=f"${pred_data['current_daily_avg']:.2f}/day",
                    delta=f"${pred_data['predicted_daily_avg'] - pred_data['current_daily_avg']:.2f}"
                )
                st.caption(f"Trend: {pred_data['trend']}")
    
    cost_data = fetch_cost_analysis()
    if isinstance(cost_data, dict) and cost_data:
        st.subheader("ğŸ“Š Cost Analysis")
        total_cost = cost_data['service_costs']['cost'].sum()
        st.metric("Total Cost", f"${total_cost:,.2f}")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Service Costs**")
            st.dataframe(
                cost_data['service_costs'].style.format({'cost': '${:,.2f}'}),
                use_container_width=True,
                hide_index=True
            )
        with col2:
            st.markdown("**Region Costs**")
            st.dataframe(
                cost_data['region_costs'].style.format({'cost': '${:,.2f}'}),
                use_container_width=True,
                hide_index=True
            )
        
        st.subheader("ğŸ¤– AI Cost Insights")
        insights = bedrock_service.generate_cost_insights(cost_data)
        if insights:
            st.markdown(insights)
        else:
            st.info("í˜„ì¬ ë¹„ìš© ë¶„ì„ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.subheader("ğŸ“ˆ Cost Visualizations")
        
        fig_pie = px.pie(
            cost_data['service_costs'],
            values='cost',
            names='SERVICE',
            title='Cost Distribution by Service'
        )
        st.plotly_chart(fig_pie, use_container_width=True)
        
        fig_bar = px.bar(
            cost_data['region_costs'],
            x='REGION',
            y='cost',
            title='Cost by Region'
        )
        st.plotly_chart(fig_bar, use_container_width=True)
        
        if 'daily_costs' in cost_data:
            fig_line = px.line(
                cost_data['daily_costs'],
                x='date',
                y='cost',
                color='SERVICE',
                title='Daily Cost Trend'
            )
            st.plotly_chart(fig_line, use_container_width=True)
    else:
        st.info("No cost analysis data available")

# íƒ­ 3: Resource Metrics
## ì„œë¹„ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­ í‘œì‹œ
## í™•ì¥ ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­ ë·° êµ¬ì„±

with tab3:
    debug_print("Rendering Resource Metrics tab")
    st.header("Resource Metrics Dashboard")
    
    selected_service = st.selectbox(
        "Select Service",
        ["EC2", "RDS", "Lambda"]
    )
    
    resources_df = fetch_aws_resources()
    if not resources_df.empty:
        service_resources = resources_df[resources_df['service_type'] == selected_service]
        
        for _, resource in service_resources.iterrows():
            print("resource :"  , resource)
            # Prepare tags output            
            tags = resource.get('tags', 'No Tags')
            try:
                if isinstance(tags, dict):                    
                    tags_output = tags.get("Name") or next(iter(tags.values()), "No Tags")
                else:
                    # If tags is not a dict, try parsing it as JSON                    
                    tags_dict = json.loads(tags)
                    tags_output = tags_dict.get("Name") or next(iter(tags_dict.values()), "No Tags")
            except Exception as e:
                tags_output = "No Tags"

           # ìƒíƒœ ìƒ‰ìƒ ì§€ì •
            status_color = "green" if resource['status'].lower() == "running" else "grey"

            # HTMLë¡œ ì œëª© êµ¬ì„±
            title_html = f"""
            <div style="border: 1px solid #ddd; padding: 10px; border-radius: 5px;">
                <b>Resource ID:</b> {resource['resource_id']} | <b>Tag:</b> {tags_output} |
                <b>Status:</b> <span style="color: {status_color};">{resource['status']}</span>
            </div>
            """

            # HTML ì œëª© í‘œì‹œ (expander ì—†ì´)
            st.markdown(title_html, unsafe_allow_html=True)
            with st.expander("View Details", expanded=False):
                if isinstance(resource.get('details'), dict):
                    metrics = resource['details'].get('metrics', {})
                    if metrics:
                        metric_cols = st.columns(len(metrics))
                        for i, (metric_name, metric_data) in enumerate(metrics.items()):
                            with metric_cols[i]:
                                st.metric(
                                    metric_name,
                                    f"{metric_data['value']} {metric_data['unit']}"
                                )
                    else:
                        st.info("No metrics available for this resource")
                else:
                    st.info("No metrics available for this resource")

# íƒ­ 4: Optimization
## ë¦¬ì†ŒìŠ¤ ìµœì í™” ì¶”ì²œ
## AIê¸°ë°˜ ìƒì„¸ ì „ëµ ì œê³µ

with tab4:
    debug_print("Rendering Optimization tab")
    st.header("Resource Optimization Recommendations")
    
    recommendations = fetch_recommendations()
    if not recommendations.empty:
        total_savings = recommendations['potential_savings'].sum()
        st.metric("ì˜ˆìƒ ì´ ì ˆê°ì•¡", f"${total_savings:.2f}")
        
        for _, rec in recommendations.iterrows():
            with st.expander(f"{rec['resource_id']} ({rec['service_type']})ì— ëŒ€í•œ ì¶”ì²œì‚¬í•­"):
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"**ìœ í˜•:** {rec['recommendation_type']}")
                    st.markdown(f"**ì‚¬ìœ :** {rec['reason']}")
                with col2:
                    st.markdown(f"**ì˜ˆìƒ ì ˆê°ì•¡:** ${rec['potential_savings']:.2f}")
                    st.markdown(f"**ê¶Œì¥ ì¡°ì¹˜:** {rec['action']}")
                
                st.subheader("ğŸ¤– AI-Generated Optimization Strategy")
                detailed_strategy = bedrock_service.enhance_recommendations(rec.to_dict())
                if detailed_strategy:
                    st.markdown(detailed_strategy)
                else:
                    st.info("í˜„ì¬ ìµœì í™” ì „ëµì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("í˜„ì¬ ê°€ëŠ¥í•œ ìµœì í™” ì¶”ì²œì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")


# íƒ­ 5: AWS Expert Chat
## AIì „ë¬¸ê°€ì™€ì˜ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì¶”ê°€
## ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬
## ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ

with tab5:
    st.header("ğŸ’¬ Chat with AWS Expert")
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    user_question = st.text_input("Ask anything about AWS:", key="aws_expert_input")
    
    if st.button("Ask Expert", key="ask_expert_button"):
        if user_question:
            try:
                # DataFrameì„ dictë¡œ ë³€í™˜
                resources_df = fetch_aws_resources()
                cost_analysis = fetch_cost_analysis()
                
                context = {
                    'resources': resources_df.to_dict(orient='records') if not resources_df.empty else [],
                    'cost_data': {
                        'service_costs': cost_analysis['service_costs'].to_dict(orient='records') if isinstance(cost_analysis, dict) and 'service_costs' in cost_analysis else [],
                        'region_costs': cost_analysis['region_costs'].to_dict(orient='records') if isinstance(cost_analysis, dict) and 'region_costs' in cost_analysis else [],
                        'daily_costs': cost_analysis['daily_costs'].to_dict(orient='records') if isinstance(cost_analysis, dict) and 'daily_costs' in cost_analysis else []
                    } if cost_analysis else {}
                }
                
                # ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ë¡œê¹…
                debug_print(f"Context data structure: {json.dumps(context, indent=2)}")
                
                response = bedrock_service.chat_with_aws_expert(user_question, context)
                
                if response:
                    st.session_state.chat_history.append({
                        "question": user_question,
                        "answer": response
                    })
                    
                    # ìµœì‹  ì‘ë‹µ í‘œì‹œ
                    st.markdown(f"**Q:** {user_question}")
                    st.markdown(f"**A:** {response}")
                    st.markdown("---")
                else:
                    st.error("Failed to get response from AWS Expert")
                    
            except Exception as e:
                st.error(f"Error processing request: {str(e)}")
                debug_print(f"Error details: {str(e)}")
        else:
            st.warning("Please enter a question first.")
    
    # ì´ì „ ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    if st.session_state.chat_history:
        st.subheader("Previous Conversations")
        for chat in reversed(st.session_state.chat_history[:-1]):  # ìµœì‹  ì‘ë‹µ ì œì™¸
            st.markdown(f"**Q:** {chat['question']}")
            st.markdown(f"**A:** {chat['answer']}")
            st.markdown("---")


# ë„ì›€ë§
with st.expander("â„¹ï¸ ë„ì›€ë§"):
    st.markdown("""
    ### ì‚¬ìš© ë°©ë²•
    1. AWS ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì§ˆë¬¸ì„ ìì—°ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”
    2. 'ë¦¬ì†ŒìŠ¤ ì¡°íšŒ' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”
    3. íŠ¹ì • ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”
    4. ë¹„ìš© ë¶„ì„ ë° ìµœì í™” ì¶”ì²œ ì‚¬í•­ì„ ê²€í† í•˜ì„¸ìš”
    
    ### ì§€ì›ë˜ëŠ” ì„œë¹„ìŠ¤
    - EC2 (ê°€ìƒ ì„œë²„ ì»´í“¨íŒ…)
    - RDS (ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤)
    - Lambda (ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ…)
    - S3 (í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€)
    
    ### ì£¼ìš” ê¸°ëŠ¥
    - ì‹¤ì‹œê°„ AWS ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
    - ë¹„ìš© ë¶„ì„ ë° ì˜ˆì¸¡
    - ë¦¬ì†ŒìŠ¤ ì„±ëŠ¥ ì§€í‘œ ì‹œê°í™”
    - ìµœì í™” ì¶”ì²œ ì‚¬í•­ ì œê³µ
    - AI ê¸°ë°˜ AWS ì „ë¬¸ê°€ ìƒë‹´
    
    ### ë°ì´í„° ì—…ë°ì´íŠ¸
    - ë¦¬ì†ŒìŠ¤ ì •ë³´: 5ë¶„ë§ˆë‹¤ ìë™ ê°±ì‹ 
    - ë¹„ìš© ë°ì´í„°: ì¼ì¼ ë‹¨ìœ„ ì—…ë°ì´íŠ¸
    - ì„±ëŠ¥ ì§€í‘œ: ì‹¤ì‹œê°„ ìˆ˜ì§‘
    
    ### ë¬¸ì˜ ì‚¬í•­
    - ê¸°ìˆ  ì§€ì›ì´ í•„ìš”í•œ ê²½ìš° AWS ì „ë¬¸ê°€ ì±„íŒ…ì„ ì´ìš©í•´ì£¼ì„¸ìš”
    - ìƒì„¸í•œ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš° ë¹„ìš© ë¶„ì„ íƒ­ì„ í™•ì¸í•´ì£¼ì„¸ìš”
    """)

# í‘¸í„°
st.markdown("---")
st.markdown("ì´ Chatbotì€ Streamlitê³¼ Amazon Bedrock Claude 3.5 Sonnetì„ ê¸°ë°˜ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤")


